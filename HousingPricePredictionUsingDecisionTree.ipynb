{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8bf303222581de137104ff94d08712557d5506a1"
   },
   "source": [
    "## Predicting the House Prices using Decision Tree Regressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Id', 'MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea', 'Street',\n",
      "       'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig',\n",
      "       'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType',\n",
      "       'HouseStyle', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd',\n",
      "       'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType',\n",
      "       'MasVnrArea', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual',\n",
      "       'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1',\n",
      "       'BsmtFinType2', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'Heating',\n",
      "       'HeatingQC', 'CentralAir', 'Electrical', '1stFlrSF', '2ndFlrSF',\n",
      "       'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath',\n",
      "       'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual',\n",
      "       'TotRmsAbvGrd', 'Functional', 'Fireplaces', 'FireplaceQu', 'GarageType',\n",
      "       'GarageYrBlt', 'GarageFinish', 'GarageCars', 'GarageArea', 'GarageQual',\n",
      "       'GarageCond', 'PavedDrive', 'WoodDeckSF', 'OpenPorchSF',\n",
      "       'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'PoolQC',\n",
      "       'Fence', 'MiscFeature', 'MiscVal', 'MoSold', 'YrSold', 'SaleType',\n",
      "       'SaleCondition', 'SalePrice'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "\n",
    "# Path of the file to read\n",
    "iowa_file_path = 'train.csv'\n",
    "\n",
    "home_data = pd.read_csv(iowa_file_path)\n",
    "print(home_data.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    208500\n",
      "1    181500\n",
      "2    223500\n",
      "3    140000\n",
      "4    250000\n",
      "Name: SalePrice, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#  target object is called y\n",
    "y = home_data.SalePrice\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X\n",
    "features = ['LotArea', 'YearBuilt', '1stFlrSF', '2ndFlrSF', 'FullBath', 'BedroomAbvGr', 'TotRmsAbvGrd']\n",
    "X = home_data[features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FITTING THE DECISION TREE MODEL\n",
    "\n",
    "### We use data to decide how to break the houses into two groups, and then again to determine the predicted price in each group. This step of capturing patterns from data is called fitting or training the model. The data used to fit the model is called the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "_uuid": "be9ab41f1bf5a5daa922643f4551773cbd374006"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=1, splitter='best')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Splitting into validation and training data\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)\n",
    "\n",
    "# Specifying Model\n",
    "iowa_model = DecisionTreeRegressor(random_state=1)\n",
    "# Fitting Model\n",
    "iowa_model.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FINDING mean absolute error (MAE) \n",
    "\n",
    "### It is a measure of difference between two continuous variables. We use it to identify how well our model is trained. Means whether it is predicting correctly or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MAE: $ 29652.931506849316\n"
     ]
    }
   ],
   "source": [
    "# Make validation predictions and calculate mean absolute error\n",
    "val_predictions = iowa_model.predict(val_X)\n",
    "val_mae = mean_absolute_error(val_predictions, val_y)\n",
    "print(\"Validation MAE: $\",val_mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "dfb53586eb0310610463a459ecb3640f96ade232"
   },
   "source": [
    "# The Mean Absolute Error is Coming $29,653 in house price prediction which is very high. \n",
    "## Now I will try to reduce the Error by checking the MAE at various Depth of the Decision tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method to calculate the MAE for a given depth/Max Leave count. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "_uuid": "cbd9b779d6ac205773775bb10c3506ccd5e3aeae"
   },
   "outputs": [],
   "source": [
    "def get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y):\n",
    "    model = DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes, random_state=0)\n",
    "    model.fit(train_X, train_y)\n",
    "    preds_val = model.predict(val_X)\n",
    "    mae = mean_absolute_error(val_y, preds_val)\n",
    "    return(mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9379cfa135e2c798df058bb6ec47f2e098ce8d36"
   },
   "source": [
    "## Step 1: Compare Different Tree Sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "_uuid": "5330c43f7cb4d7f701fbe4160cb3e044c9e94949"
   },
   "outputs": [],
   "source": [
    "candidate_max_leaf_nodes = [5, 25, 50, 100, 250, 500]\n",
    "#  finding the ideal tree size from candidate_max_leaf_nodes\n",
    "min_err=0\n",
    "size=0\n",
    "for x in candidate_max_leaf_nodes:\n",
    "    mae=get_mae(x,train_X, val_X, train_y, val_y)\n",
    "    if min_err==0 or mae<min_err:\n",
    "      min_err=mae\n",
    "      size=x \n",
    "    \n",
    "\n",
    "# Storing the best value of max_leaf_nodes (it will be either 5, 25, 50, 100, 250 or 500)\n",
    "best_tree_size =size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d1d217dfd0664fc209da9b8401c155b032670575"
   },
   "source": [
    "## Step 2: Fit Model Using All Data\n",
    "\n",
    "As we know the best tree size. Now deploying this model in practice. We will make it even more accurate by using all of the data and keeping that tree size. That is, now we don't need to hold out the validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "_uuid": "0663dd99ec94e058eb5d8d183a6e92980d4a4a79"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "           max_leaf_nodes=100, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=1, splitter='best')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filling in argument to make optimal size \n",
    "final_model = DecisionTreeRegressor(max_leaf_nodes=best_tree_size,random_state=1)\n",
    "\n",
    "# fitting the final model\n",
    "final_model.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean_absolute_error in Predicted house price is $ 22762.42931506849\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "forest_model = RandomForestRegressor(random_state=1)\n",
    "forest_model.fit(train_X, train_y)\n",
    "melb_preds = forest_model.predict(val_X)\n",
    "print(\"The mean_absolute_error in Predicted house price is $\", mean_absolute_error(val_y, melb_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "55c228c50771e730cbbeb09fcf61e245c8fa86d2"
   },
   "source": [
    "The model is tuned and we can see improved results. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "eb0c4dcc17740b7700a6697c7bd7f25b2af4c594"
   },
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
